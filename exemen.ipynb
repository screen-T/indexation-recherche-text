{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhFyJEFUShfDzufkEbPrid",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/screen-T/indexation-recherche-text/blob/main/exemen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-w9InZCU8fK"
      },
      "outputs": [],
      "source": [
        "import nltk \n",
        "nltk.download()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "3wCudlAOZY9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import math\n",
        "from nltk.corpus import stopwords\n",
        "from collections import defaultdict\n",
        "import os, sys\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "path = \"/content/sample_data/corpus\"\n",
        "dirs = os.listdir( path )\n",
        "#founction pour la liste des mots stem\n",
        "def stem_function(file):\n",
        "  tokens=[]\n",
        "  nl=[]\n",
        "  path = \"/content/sample_data/corpus\"\n",
        "  f=open(os.path.join(path, file))\n",
        "  text=f.read()  \n",
        "  tokens = nltk.word_tokenize(text)\n",
        "  for i in tokens:\n",
        "    if i not in stopwords.words('french'): \n",
        "      nl.append(i)\n",
        "  stemmer = PorterStemmer()\n",
        "  ftokens=[stemmer.stem(token) for token in nl]\n",
        "  return ftokens  \n",
        "#nombre d'apparition dans chaque document\n",
        "def TermF_function(tokens):\n",
        "  tfdict={}\n",
        "  for t in tokens:\n",
        "    if t not in tfdict:\n",
        "        tfdict[t] = 1\n",
        "    elif t in tfdict:\n",
        "        tfdict[t] += 1\n",
        "  return tfdict\n",
        "res={}\n",
        "# fonction de dict globale \n",
        "def dic(k):\n",
        "  for  i in k:\n",
        "     if i in res:\n",
        "       res[i]=res[i]+k[i]\n",
        "     else:\n",
        "       res[i]=k[i]\n",
        "#affichage de dicionaire globale \n",
        "for file in dirs:\n",
        "   c={}\n",
        "   x=stem_function(file)\n",
        "   k=TermF_function(x)\n",
        "   dic(k)\n",
        "print(res)\n",
        "# compute IDF pour chaque mots avec l'utilisation du formule de log(n/ni) \n",
        "N = len(dirs)\n",
        "idf_dict = defaultdict(int)\n",
        "for file in dirs:\n",
        "  x = stem_function(file)\n",
        "  k = TermF_function(x)\n",
        "  for word in k:\n",
        "    idf_dict[word] += 1\n",
        "for word in idf_dict:\n",
        "  idf_dict[word] = math.log(N / idf_dict[word])\n",
        "# calcule de poid dans chaque document pour chaque mot\n",
        "poids = defaultdict(dict)\n",
        "for file in dirs:\n",
        "  x = stem_function(file)\n",
        "  k = TermF_function(x)\n",
        "  for word in k:\n",
        "    tf = k[word]\n",
        "    idf = idf_dict[word]\n",
        "    poids[file][word] = tf * idf\n",
        "# print the poids for each document\n",
        "''' for file in dirs:\n",
        "  print(\"****** poids for document\", file)\n",
        "  for word in poids[file]:\n",
        "    print(word, poids[file][word]) '''\n",
        "# write inverted file to a file\n",
        "with open(\"fich-inv.txt\", \"w\") as f:\n",
        "  for stem in poids:\n",
        "    f.write(stem + \"----\")\n",
        "    for doc_id in poids[stem]:\n",
        "      f.write(doc_id + \"-----\" + str(poids[stem][doc_id]) + \"\")\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "\n",
        "#saisie la requte\n",
        "def saisie_requte():\n",
        " n=input(\"saisie votre requte: \")\n",
        " return n\n",
        "requte=saisie_requte()\n",
        "print(requte)\n",
        "#retrouver les tokens et enléve les stopwords et stem les mots de la requte\n",
        "def requte_stem_function(requte):\n",
        "  tokens=[]\n",
        "  nl=[]\n",
        "  tokens = nltk.word_tokenize(requte)\n",
        "  for i in tokens:\n",
        "    if i not in stopwords.words('french'): \n",
        "      nl.append(i)\n",
        "  stemmer = PorterStemmer()\n",
        "  ftokens=[stemmer.stem(token) for token in nl]\n",
        "  return ftokens  \n",
        "requet_tokens=requte_stem_function(requte)\n",
        "print(requet_tokens)\n",
        "\n",
        "\n",
        "def recherche(requte, poids, dirs):\n",
        "    # Tokenize la requête et effectue le stemming\n",
        "    requte_tokens = requte_stem_function(requte)\n",
        "    # Calcule le vecteur de requête\n",
        "    requte_vecteur = [requte_tokens.count(word) * idf_dict[word] for word in requte_tokens]\n",
        "    # Calcule la similarité cosinus entre la requête et chaque document\n",
        "    scores = {}\n",
        "    for file in dirs:\n",
        "        score = 0\n",
        "        for word in requte_tokens:\n",
        "            if word in poids[file]:\n",
        "                score += poids[file][word] * requte_vecteur[requte_tokens.index(word)]\n",
        "        scores[file] = score\n",
        "    # Trie les documents par ordre de pertinence décroissant\n",
        "    documents_pertinents = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)\n",
        "    # Renvoie la liste des documents pertinents triés par ordre de pertinence ainsi que les scores correspondants\n",
        "    return documents_pertinents, scores\n",
        "# Effectue la recherche et renvoie une liste de documents pertinents triés par ordre de pertinence ainsi que les scores correspondants\n",
        "documents_pertinents, scores = recherche(requte, poids, dirs)\n",
        "# Affiche la liste des documents pertinents triés par ordre de pertinence et leurs scores correspondants\n",
        "for doc in documents_pertinents:\n",
        "    print(doc, scores[doc])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0OOwGfxZ0CD",
        "outputId": "16a3d56d-8382-4da0-fa80-813797e93338"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'il': 5, 'dit': 13, 'non': 3, 'tête': 2, 'oui': 3, 'coeur': 3, '’': 87, 'aim': 5, 'professeur': 2, 'debout': 1, 'questionn': 1, 'tou': 9, 'problèm': 1, 'posé': 1, 'soudain': 2, 'fou': 1, 'rire': 1, 'prend': 1, 'effac': 1, 'tout': 18, 'chiffr': 1, 'mot': 5, 'date': 1, 'nom': 3, 'phrase': 1, 'pièg': 1, 'malgré': 1, 'menac': 1, 'maîtr': 3, 'sou': 1, 'huée': 1, 'enfant': 14, 'prodig': 1, 'crai': 1, 'couleur': 1, 'tableau': 1, 'noir': 3, 'malheur': 1, 'dessin': 1, 'visag': 3, 'bonheur': 1, '.': 13, 'a': 21, 'appel': 3, 'aimé': 1, 'bienvenu': 1, 'désiré': 1, 'appelé': 1, 'destiné': 1, 'je': 7, 'sai': 7, 'pourquoi': 2, 'donné': 2, 'nom-là': 1, 'mai': 4, 'chanc': 1, 'on': 2, 'pu': 1, 'bon': 2, 'rien': 6, 'mauvais': 1, 'grain': 1, 'détesté': 1, 'méprisé': 1, 'perdu': 1, 'jamai': 1, 'vou': 2, 'regard': 4, 'vie': 2, 'plu': 7, 'j': 2, 'cela': 3, 'seul': 1, 'voit': 2, 'ceux': 1, 'donnent': 1, 'droit': 1, 'être': 2, 'ang': 4, 'c': 4, 'étrang': 6, 'âne': 4, 'étrâne': 2, 'veut': 2, 'dire': 3, 'haussant': 1, 'ail': 1, 'pourtant': 1, 'si': 4, 'quelqu': 2, 'chose': 3, '!': 5, 'tapant': 1, 'pie': 6, 'étranger': 2, 'vous-mêm': 1, 'et': 19, 'envol': 1, 'le': 3, 'tendr': 1, 'dangereux': 1, 'amour': 2, 'apparu': 1, 'soir': 3, 'aprè': 1, 'trop': 3, 'long': 1, 'jour': 2, 'peut-êtr': 6, 'archer': 1, 'arc': 1, 'bien': 4, 'musicien': 2, 'harp': 1, 'blessé': 3, 'flèche': 1, 'chanson': 2, 'toujour': 1, 'brûlant': 2, 'blessur': 1, 'interdit': 1, 'fair': 3, 'musiqu': 3, 'vingt-quatr': 1, 'heur': 1, 'ça': 2, 'finira': 1, 'tort': 2, 'hier': 1, 'hindou': 1, 'amnésiqu': 1, 'mi': 2, 'souvenir': 4, 'gross': 2, 'boul': 3, 'or': 2, 'roulé': 1, 'fond': 3, 'corridor': 1, 'pui': 3, 'escali': 1, 'dégringolé': 1, 'renvers': 1, 'monsieur': 2, 'devant': 2, 'loge': 1, 'concierg': 1, 'voulait': 3, 'rentrant': 1, 'jeté': 2, 'place': 1, 'sien': 1, 'mainten': 3, 'voilà': 2, 'tranquil': 2, 'petit': 6, 'bout': 2, 'temp': 1, 'pri': 1, 'souvien': 2, 'parti': 1, 'sanglot': 1, 'tomb': 1, 'grand-pèr': 1, 'paternel': 1, 'judicieux': 1, 'éleveur': 1, 'sauterel': 1, 'homm': 2, 'valait': 1, 'grand': 7, 'peur': 2, 'portait': 1, 'bretel': 1, 'mauv': 3, 'sa': 1, 'femm': 1, 'appelait': 1, 'vaurien': 1, 'saurien': 2, 'croi': 1, 'autr': 3, 'est-c': 3, 'futilité': 1, 'tiroir': 1, 'miett': 1, 'gravat': 1, 'mémoir': 4, 'connai': 1, 'fin': 1, 'histoir': 1, 'comment': 1, 'est-el': 1, 'fait': 2, 'quoi': 2, 'a-t-el': 1, 'air': 2, 'aura-t-el': 1, 'tard': 2, 'vert': 1, 'vacanc': 1, 'devenu': 1, 'panier': 1, 'osier': 1, 'sanglant': 1, 'mond': 1, 'assassiné': 1, 'dedan': 1, 'étiquett': 1, 'haut': 1, 'ba': 1, 'fragil': 1, 'lettr': 1, 'roug': 1, 'bleue': 1, 'enfin': 1, 'grise': 1, 'rose': 1, 'puisqu': 1, 'choix': 1, 'en': 1, 'sortant': 1, 'école': 1, 'rencontré': 4, 'chemin': 4, 'fer': 5, 'emmené': 1, 'autour': 7, 'terr': 7, 'wagon': 1, 'doré': 2, 'mer': 6, 'promenait': 1, 'coquillag': 1, 'île': 1, 'parfumé': 1, 'beaux': 1, 'naufrag': 1, 'saumon': 1, 'fumé': 1, 'au-dessu': 1, 'lune': 2, 'étoil': 2, 'bateau': 2, 'voil': 2, 'partant': 1, 'japon': 1, 'troi': 1, 'mousquetair': 1, 'cinq': 1, 'doigt': 1, 'main': 1, 'tournant': 1, 'manivel': 1, 'sous-marin': 1, 'plongeant': 1, 'chercher': 1, 'oursin': 1, 'reven': 1, 'voie': 2, 'maison': 2, 'fuyait': 4, 'hiver': 2, 'attrap': 1, 'rouler': 2, 'derrièr': 1, 'écrasé': 1, 'arrêté': 1, 'printemp': 1, 'salué': 1, 'garde-barrièr': 1, 'remercié': 1, 'fleur': 1, 'mise': 1, 'pousser': 2, 'traver': 1, 'avanc': 1, 'abîmer': 1, 'alor': 3, 'revenu': 1, 'soleil': 2, 'cheval': 1, 'voitur': 1, 'deux': 9, 'quatr': 10, 'huit': 11, 'font': 6, 'seize…': 2, 'répétez': 2, 'oiseau-lyr': 2, 'qui': 1, 'pass': 1, 'ciel': 1, 'l': 5, 'entend': 3, ':': 2, 'sauve-moi': 1, 'joue': 5, 'oiseau': 5, 'descend': 1, 'quatre…': 1, 'lui…': 1, 'seiz': 5, '?': 1, 'surtout': 1, 'trente-deux': 1, 'de': 1, 'façon': 1, 'vont': 4, 'caché': 1, 'dan': 1, 'pupitr': 2, 'tour': 2, 'fichent': 1, 'camp': 1, 'ni': 2, 'un': 1, 'également': 1, 'chant': 1, 'crie': 1, 'quand': 1, 'fini': 1, 'pitr': 1, 'écoutent': 1, 'mur': 1, 'class': 1, 's': 1, 'écroulent': 1, 'vitr': 1, 'redevienn': 2, 'sabl': 1, 'encr': 1, 'redevi': 3, 'eau': 2, 'arbr': 1, 'la': 1, 'craie': 1, 'falais': 1, 'porte-plum': 1, 'kabyl': 1, 'chapel': 1, 'quai': 1, 'javel': 1, 'pay': 2, 'lointain': 1, 'cobay': 1, 'coloni': 1, 'doux': 1, 'adolesc': 1, 'port': 2, 'itali': 1, 'boumian': 1, 'saint-ouen': 1, 'apatrid': 1, 'aubervilli': 1, 'brûleur': 1, 'ordur': 1, 'vill': 2, 'pari': 1, 'ébouillanteur': 1, 'bête': 1, 'trouvé': 1, 'mort': 1, 'beau': 1, 'milieu': 1, 'rue': 4, 'tunisien': 1, 'grenel': 1, 'embauché': 1, 'débauché': 1, 'manoeuvr': 1, 'désoeuvré': 1, 'polack': 1, 'marai': 1, 'templ': 1, 'rosier': 1, 'cordonni': 1, 'cordou': 1, 'soutier': 1, 'barcelon': 1, 'pêcheur': 1, 'baléar': 1, 'finisterr': 1, 'rescapé': 1, 'franco': 1, 'déporté': 1, 'franc': 1, 'navarr': 1, 'avoir': 1, 'défendu': 1, 'vôtre': 1, 'liberté': 1, 'esclav': 2, 'fréju': 2, 'tiraillé': 1, 'parqué': 1, 'bord': 1, 'où': 1, 'peu': 1, 'baignez': 1, 'évoquez': 1, 'chaqu': 1, 'locaux': 1, 'disciplinair': 1, 'vieill': 1, 'boît': 1, 'cigar': 1, 'fil': 1, 'écho': 1, 'villag': 1, 'oiseaux': 1, 'forêt': 1, 'venez': 1, 'capital': 1, 'fêter': 1, 'cadencé': 1, 'prise': 1, 'bastil': 1, 'quatorz': 1, 'juillet': 1, 'sénégal': 1, 'dépatrié': 1, 'expatrié': 1, 'naturalisé': 1, 'indochinoi': 1, 'jongleur': 1, 'innoc': 1, 'couteaux': 2, 'vendiez': 1, 'autrefoi': 1, 'terrass': 1, 'café': 1, 'joli': 1, 'dragon': 1, 'papier': 2, 'plié': 1, 'tôt': 1, 'grandi': 1, 'vite': 1, 'allé': 1, 'dormez': 1, 'aujourd': 1, 'hui': 1, 'retour': 1, 'bomb': 1, 'incendiair': 1, 'labour': 1, 'rizièr': 1, 'renvoyé': 1, 'monnai': 1, 'retourné': 1, 'do': 1, 'mal': 1, 'vivez': 1, 'mourez': 1, 'sali': 1, 'excus': 1, 'homme-sandwich': 1, 'prospectu': 1, 'armé': 1, 'salut': 1, 'là': 1, 'froissé': 1, 'ruisseau': 1, 'couler': 1, 'pardonnez-moi': 1, 'cett': 1, 'offens': 1, 'éboueur': 2, 'passer': 1, 'valet': 1, 'mécaniqu': 1, 'effacé': 1, 'dirai': 1, 'salu': 2, 'plein': 2, 'ogress': 1, 'charmant': 1, 'comm': 1, 'cont': 1, 'chinoi': 1, 'plantent': 1, 'épée': 1, 'cristal': 1, 'plaisir': 1, 'plaie': 1, 'heureus': 1, 'désir': 1, 'grâce': 1}\n",
            "saisie votre requte: des cinq doigts de la main tournant ma manivelle d’un petit sous-marin plongeant au fond des mers pour chercher des oursins\n",
            "des cinq doigts de la main tournant ma manivelle d’un petit sous-marin plongeant au fond des mers pour chercher des oursins\n",
            "['cinq', 'doigt', 'main', 'tournant', 'manivel', '’', 'petit', 'sous-marin', 'plongeant', 'fond', 'mer', 'chercher', 'oursin']\n",
            "doc9.txt 64.70837587174346\n",
            "doc5.txt 8.079681815073387\n",
            "doc1.txt 6.938941934649612\n",
            "doc3.txt 0.0\n",
            "doc8.txt 0.0\n",
            "doc4.txt 0.0\n",
            "doc6.txt 0.0\n",
            "doc10.txt 0.0\n",
            "doc2.txt 0.0\n",
            "doc7.txt 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "UHM8ldjVaIQX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}